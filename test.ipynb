{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/p/project/medvl/users/tahir/ExplainSegmentVLM/openclip_install/.explainsegmentVLM_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/p/project/medvl/users/tahir/ExplainSegmentVLM/openclip_install/.explainsegmentVLM_env/lib/python3.8/site-packages/spacy/language.py:2141: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n",
      "/p/project/medvl/users/tahir/ExplainSegmentVLM/openclip_install/.explainsegmentVLM_env/lib/python3.8/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name vit_large_patch14_224_clip_laion2b to current vit_large_patch14_clip_224.laion2b.\n",
      "  model = create_fn(\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST COMPLETE\n"
     ]
    }
   ],
   "source": [
    "import open_clip \n",
    "from open_clip import create_model_and_transforms, get_tokenizer\n",
    "import textwrap\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from os.path import exists\n",
    "from urllib.parse import urlparse\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve                \n",
    "from sklearn.metrics import precision_recall_curve  \n",
    "from sklearn.metrics import f1_score               \n",
    "from sklearn.metrics import fbeta_score\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Union\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import requests\n",
    "from PIL import Image\n",
    "import multiprocessing # CPU parallelization\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Lock\n",
    "lock = Lock()\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP   # GPU parallelization\n",
    "import tarfile \n",
    "from io import BytesIO\n",
    "import time\n",
    "import spacy\n",
    "import scispacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "biomednlp = spacy.load(\"en_core_sci_lg\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import argparse\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "#custom modules\n",
    "#from training.saliency import plot_saliency_map,sliding_window_largestride, get_random_crop_params,get_random_crop_params_fixedcropsize,sliding_window,get_cropped_image,update_saliency_map,cosine_similarity\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# replace PATH to the model with yours\n",
    "model, preprocess_train, preprocess_val = create_model_and_transforms(\"hf-hub_microsoft_pretrained_laion_large\", pretrained='/p/project/medvl/models/newest_caption_title_umls_sentence_umls.pt') \n",
    "tokenizer = open_clip.get_tokenizer(\"hf-hub_microsoft_pretrained_laion_large\")\n",
    "val_data = \"/p/scratch/medvl/data/val/val_00000.tar\"\n",
    "base_path = '/p/project/medvl/users/tahir/bestmodel/val_data'\n",
    "precision = \"amp\"\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"TEST COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".explainVLM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
